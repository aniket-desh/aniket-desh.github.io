<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link href="https://fonts.googleapis.com/css2?family=Vollkorn:wght@400;600&display=swap" rel="stylesheet">
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link rel="stylesheet" href="style.css">
  <title>research</title>
</head>

<body>
  <div id="contentContainer">

    <div class="top-link">
        <a href="about.html">&larr; back</a>
    </div>

    <h2 class="katex-title">Research</h2>
    <hr>

    <div class="profile-section">
      <!-- <img src="assets/ad.png" alt="Profile Photo" class="profile-photo"> -->

      <div class="bio-text">
        <p> <b><a href="https://lpna.cs.illinois.edu/" class="katex-title" style="font-size:inherit; font-weight:500;" target="_blank">Lab for Parallel Numerical Algorithms</a></b> <br>
            Currently, I am studying probabilistic methods for estimating the contraction of closed tensor networks. We are developing a Markov chain Monte Carlo algorithm, borrowing methods from statistical physics, to estimate contractions such as the trace of matrix products.
        </p>
        <p>
            For example, consider the following tensor contraction
            \[
                \text{Tr}(ABCD) = \sum_{ijkl} A_{ij}B_{jk}C_{kl}D_{li}
            \]
            This is a closed ring network (all indices are contracted). The direct computation requires multiple matrix multiplications, an \(\mathcal{O}(n^3)\) operation. However, we can use MCMC methods to estimate contractions. To improve mixing, we borrow some clever sampling techniques from statistical physics.
        </p>
        <p>
          While this is a somewhat trivial contraction (direct multiplication is often faster in this case), finding an optimal contraction order for larger networks is \( \mathsf{\#P} \)-hard. High state-space systems, such as those arising in quantum chemistry and quantum circuits, would benefit greatly from effective contraction approximation algorithms.
        </p>
        More updates soon!
      </div>
      

      <div class="bio-text">
        <p> 
          <b><a href="https://conelab.beckman.illinois.edu/" class="katex-title" style="font-size:inherit; font-weight:500;" target="_blank">Computation & Neurodynamics Lab</a></b> <br>
          I study the dynamics of stochastic neuronal populations using moment closure methods. Starting from nonlinear SDEs that describe individual neuron behavior, we analytically derive reduced ODEs governing the evolution of the population mean and covariance. This requires evaluating Jacobians, stochastic forcing terms, and closure approximations to capture the effect of higher-order moments.
        </p>
        <p>
          The system under consideration takes the form
          \[
            dx = f(x, \lambda) \, dt + G(x, \lambda) \, dW_t
          \]
          where \(x(t)\) is the neuronal state (e.g., membrane voltage and recovery variable), \(\lambda\) encodes input heterogeneity across the population, and \(W_t\) is vector-valued white noise. Nonlinearities in \(f\) (e.g., cubic terms or feedback) make exact inference intractable, so we evolve only the first two moments, which often suffice to capture collective dynamics.
        </p>
        <p>
          The closure equations are symbolically derived using <code style="font-size:0.92em;">sympy</code> and validated against Monte Carlo simulations. We’re now analyzing these ODEs through the lens of symmetry and geometric structure: computing Lie brackets between the dynamics and candidate vector fields to uncover invariants, symmetry-preserving perturbations, and coordinate-free signatures of neural computation.
        </p>
        <p>
          Current experiments include building surrogate models that learn the map \((\lambda, t) \mapsto (\mu(t), \Sigma(t))\), benchmarking architectures (e.g., neural nets vs. GPR), and extending the framework to rich biophysical models such as FitzHugh–Nagumo. Full implementation is on <a href="https://github.com/aniket-desh/fitzhugh-nagumo" class="katex-title" style="font-size:inherit; font-weight:500;" target="_blank">GitHub</a>.
        </p>
        More updates soon!
      </div>
    </div>


    <!-- <h2>Other</h2>

    <p>
        Materials from past applications and proposals can be found <a href="#">here</a>.
    </p> -->

    <div class="menu">
      <p>
        <a href="index.html">home</a> /
        <a href="notes.html">notes</a> /
        <a href="blog.html">blog</a> /
        <a href="../cv/cv.pdf">vitae</a>
      </p>
    </div>

  </div>
</body>

</html>
